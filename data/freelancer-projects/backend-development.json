[
  {
    "title": "Ölçeklenebilir API Gateway Mimarisi",
    "description": "<p>Mevcut mikroservis ekosistemimizde, servis sayısının 50'yi geçmesiyle birlikte merkezi yönetim ve güvenlik konusunda ciddi darboğazlar yaşamaya başladık. Servisler arası iletişimi standartlaştırmak ve dış dünyadan gelen trafiği güvenli bir şekilde karşılamak adına, özelleştirilmiş ve yüksek performanslı bir API Gateway çözümüne ihtiyacımız var.</p><p><strong>Proje kapsamındaki temel gereksinimlerimiz şunlardır:</strong></p><ul><li><strong>Teknoloji Seçimi:</strong> Kong veya Apache APISIX tabanlı, plugin geliştirilebilir bir yapı kurulmalıdır.</li><li><strong>Kimlik Doğrulama:</strong> Tüm servislerin önünde duracak merkezi bir JWT doğrulama ve OAuth2 entegrasyonu sağlanmalı, yetkisiz erişimler gateway seviyesinde engellenmelidir.</li><li><strong>Trafik Yönetimi:</strong> Anlık trafik artışlarına (spike) karşı 'Rate Limiting' ve 'Throttling' kuralları, hem IP bazlı hem de kullanıcı bazlı olarak dinamik şekilde yapılandırılabilmelidir.</li><li><strong>Dönüşüm Katmanı:</strong> Eski sistemlerden gelen XML isteklerini JSON'a, veya tam tersi dönüşümleri 'on-the-fly' yapabilen bir request/response transformasyon katmanı yazılmalıdır.</li><li><strong>Güvenlik ve İzleme:</strong> Olası DDoS saldırılarını mitigate edecek kurallar eklenmeli ve tüm trafik ELK stack üzerine loglanarak görsel dashboard'lar hazırlanmalıdır.</li></ul><p>Sistemin kesintisiz çalışması (High Availability) ve deployment süreçlerinin CI/CD pipeline'ına entegre edilmesi projenin kabul kriterleri arasındadır. Teslimatın detaylı mimari dokümantasyon ve load test raporları ile yapılmasını bekliyoruz.</p>",
    "budget": 8500,
    "deadline": "2025-04-30T00:00:00.000Z",
    "status": "open"
  },
  {
    "title": "Gerçek Zamanlı Bildirim Servisi",
    "description": "<p>E-ticaret platformumuzda Black Friday gibi yoğun kampanya dönemlerinde müşterilerimize anlık sipariş durumu ve kampanya bildirimlerini iletmekte gecikmeler yaşıyoruz. Mevcut polling tabanlı yapıyı terk edip, milyonlarca kullanıcıya milisaniyeler içinde ulaşabilecek, event-driven (olay tabanlı) bir bildirim orkestrasyon servisi kurmak istiyoruz.</p><p><strong>Beklenen teknik özellikler ve işlevler:</strong></p><ul><li><strong>WebSocket Altyapısı:</strong> 1 milyon eşzamanlı bağlantıyı (concurrent connections) kaldırabilecek, Socket.io veya ham WebSocket tabanlı ölçeklenebilir bir cluster kurulmalıdır.</li><li><strong>Çoklu Kanal Desteği:</strong> Sistem tek bir API üzerinden hem Mobil Push (FCM/APNS), hem SMS, hem de E-posta gönderimlerini yönetebilmeli ve önceliklendirebilmelidir.</li><li><strong>Kuyruk Yönetimi:</strong> RabbitMQ veya Kafka kullanılarak, yüksek hacimli bildirim istekleri asenkron olarak işlenmeli ve sistemin tıkanması önlenmelidir.</li><li><strong>Hata Toleransı:</strong> Gönderim başarısız olduğunda (örneğin kullanıcı offline ise veya 3. parti servis yanıt vermiyorsa) 'Exponential Backoff' stratejisi ile retry mekanizması devreye girmelidir.</li><li><strong>Kişiselleştirme:</strong> Bildirim içerikleri, kullanıcı adlarına veya ilgi alanlarına göre dinamik şablon motorları (Handlebars/Mustache) kullanılarak render edilmelidir.</li></ul><p>Proje sonunda, gönderilen, iletilen ve okunan bildirimlerin istatistiklerini görebileceğimiz bir admin paneli backend'i de talep edilmektedir.</p>",
    "budget": 7800,
    "deadline": "2025-04-20T00:00:00.000Z",
    "status": "open"
  },
  {
    "title": "Veri Senkronizasyon ve Replikasyon Sistemi",
    "description": "<p>Farklı coğrafi bölgelerde bulunan şubelerimizdeki yerel veritabanları ile merkez ofisteki ana veri ambarı arasında yaşanan veri tutarsızlıkları operasyonel hatalara neden olmaktadır. Bu sorunu çözmek için, internet kesintilerine dayanıklı, çift yönlü (bidirectional) çalışabilen sağlam bir veri senkronizasyon motoru geliştirilmesini talep ediyoruz.</p><p><strong>Çözülmesi gereken kritik noktalar:</strong></p><ul><li><strong>Çatışma Çözümü (Conflict Resolution):</strong> Aynı veri üzerinde hem şubede hem merkezde değişiklik yapılması durumunda, önceden belirlenen iş kurallarına (timestamp veya merkez önceliği) göre çatışmayı otomatik çözen algoritmalar geliştirilmelidir.</li><li><strong>Change Data Capture (CDC):</strong> Veritabanı loglarını dinleyerek (Debezium vb. kullanarak) değişiklikleri anlık yakalayan ve polling maliyetinden kurtaran bir yapı kurulmalıdır.</li><li><strong>Veri Bütünlüğü:</strong> Transfer sırasında veri kaybını önlemek için 'Transactional Outbox' pattern uygulanmalı ve veri bütünlüğü hash kontrolleri ile doğrulanmalıdır.</li><li><strong>Performans:</strong> Büyük veri setlerinin (bulk data) ilk senkronizasyonu sırasında ağ trafiğini boğmayacak sıkıştırma ve parçalama (chunking) yöntemleri kullanılmalıdır.</li><li><strong>İzlenebilirlik:</strong> Hangi şubenin ne zaman senkronize olduğunu, oluşan hataları ve gecikme sürelerini (lag) gösteren bir monitoring API'si yazılmalıdır.</li></ul><p>Sistem PostgreSQL ve MongoDB veritabanları arasında uyumlu çalışmalı ve Docker container yapısında teslim edilmelidir.</p>",
    "budget": 9200,
    "deadline": "2025-05-10T00:00:00.000Z",
    "status": "open"
  },
  {
    "title": "Dosya İşleme ve Dönüştürme Servisi",
    "description": "<p>Medya ajansımız için, müşterilerin yüklediği yüksek boyutlu ham video ve görselleri otomatik olarak işleyip, web ve mobil uyumlu formatlara dönüştürecek bir backend mikroservisi yazdırmak istiyoruz. Mevcut manuel süreçlerimiz çok yavaş işliyor ve sunucularımızı kilitliyor; bu nedenle tamamen asenkron ve dağıtık bir yapıya geçmemiz şart.</p><p><strong>İstenen özellikler şunlardır:</strong></p><ul><li><strong>Format Desteği:</strong> Sisteme yüklenen .MOV, .AVI videoları FFmpeg kullanılarak HLS (.m3u8) formatına, görseller ise WebP formatına otomatik dönüştürülmelidir.</li><li><strong>Kuyruk Mimarisi:</strong> Yüklenen dosyalar bir iş kuyruğuna (Redis/BullMQ) alınmalı ve arka planda çalışan worker'lar tarafından sırayla işlenmelidir.</li><li><strong>Depolama Entegrasyonu:</strong> İşlenen dosyalar doğrudan AWS S3 veya Google Cloud Storage bucket'larına yüklenmeli, sunucu diskinde yer kaplamamalıdır.</li><li><strong>Durum Bildirimi:</strong> Uzun süren video işleme süreçlerinde, kullanıcıya ilerleme durumunu (%20, %50, Bitti vb.) gösterebilmek için WebSocket veya Server-Sent Events (SSE) kullanılmalıdır.</li><li><strong>Hata Yönetimi:</strong> Bozuk dosya yüklemeleri veya dönüştürme hataları loglanmalı, kullanıcıya anlamlı bir hata mesajı dönülmeli ve admin paneline alert gönderilmelidir.</li></ul><p>Sistemin, yoğun yük altında otomatik olarak yeni worker sunucuları açabilecek (auto-scaling) bir yapıda kurgulanması gerekmektedir.</p>",
    "budget": 6500,
    "deadline": "2025-03-28T00:00:00.000Z",
    "status": "open"
  },
  {
    "title": "Ödeme İşleme ve Faturalandırma Sistemi",
    "description": "<p>Global ölçekte hizmet veren SaaS platformumuz için, farklı ülkelerdeki vergi mevzuatlarına uyumlu, çoklu para birimi destekleyen ve güvenliği en üst düzeyde tutan merkezi bir ödeme gateway katmanı geliştirmeyi hedefliyoruz.</p><p><strong>Projenin teknik detayları ve gereksinimleri:</strong></p><ul><li><strong>Provider Agnostic Yapı:</strong> Stripe, PayPal, Iyzico gibi farklı ödeme sağlayıcılarını tek bir arayüz arkasında soyutlayan (Adapter Pattern) esnek bir mimari kurulmalıdır.</li><li><strong>Abonelik Yönetimi:</strong> Deneme süreleri, 'prorated' (kıst-elyevm) ücretlendirmeler, paket yükseltme/düşürme senaryoları ve başarısız ödeme tekrarları (dunning management) otomatik yönetilmelidir.</li><li><strong>Güvenlik ve Uyumluluk:</strong> Kredi kartı bilgileri sistemimizde tutulmadan (tokenization), PCI-DSS standartlarına tam uyumlu bir akış tasarlanmalı ve 3D Secure 2.0 desteği sağlanmalıdır.</li><li><strong>Otomatik Faturalama:</strong> Her başarılı işlem sonrası, kullanıcının ülkesine ait KDV oranlarını hesaplayıp PDF formatında resmi fatura oluşturan ve e-posta ile ileten bir modül yazılmalıdır.</li><li><strong>Fraud Kontrolü:</strong> Şüpheli işlem kalıplarını (örn: aynı IP'den çok sayıda deneme) tespit edip engelleyen basit bir kural motoru sisteme entegre edilmelidir.</li></ul><p>Tüm finansal işlemlerin 'double-entry bookkeeping' mantığıyla veritabanına kaydedilmesi ve kesin tutarlılığın sağlanması zorunludur.</p>",
    "budget": 9500,
    "deadline": "2025-04-25T00:00:00.000Z",
    "status": "open"
  },
  {
    "title": "Arama Motoru ve İndeksleme Servisi",
    "description": "<p>Mevcut SQL veritabanımızdaki 'LIKE' sorguları, 5 milyon satırlık ürün envanterimizde performans sorunlarına yol açıyor. Kullanıcılarımızın aradıkları ürünleri milisaniyeler içinde bulabilmesi ve yazım hatalarına takılmadan doğru sonuçlara ulaşabilmesi için Elasticsearch tabanlı gelişmiş bir arama servisine geçiş yapmak istiyoruz.</p><p><strong>Beklenen yetenekler:</strong></p><ul><li><strong>Full-Text ve Fuzzy Search:</strong> Kullanıcı 'telfon' yazsa bile 'telefon' sonuçlarını getirebilecek, Türkçe karakter ve morfoloji desteği olan bir yapı kurulmalıdır.</li><li><strong>Faceted Search (Filtreleme):</strong> Arama sonuçlarının marka, fiyat aralığı, renk, beden gibi dinamik özelliklere göre hızlıca filtrelenebilmesi (aggregation) sağlanmalıdır.</li><li><strong>Gerçek Zamanlı İndeksleme:</strong> Veritabanına yeni bir ürün eklendiğinde veya fiyatı değiştiğinde, bu değişikliğin maksimum 1-2 saniye içinde arama motoruna yansıması (Sync Mechanism) gerekmektedir.</li><li><strong>Sıralama Algoritması:</strong> Stok durumu, popülerlik, kullanıcı puanı ve sponsorlu ürün durumuna göre özelleştirilebilir bir 'boost' (ağırlıklandırma) mantığı kurgulanmalıdır.</li><li><strong>Otomatik Tamamlama:</strong> Arama çubuğuna yazarken 'Suggest' ve 'Autocomplete' özelliklerini destekleyen, hızlı yanıt veren API endpoint'leri geliştirilmelidir.</li></ul><p>Proje kapsamında, mevcut verilerin Elasticsearch kümesine (cluster) ilk aktarımını yapacak migration script'lerinin de hazırlanması gerekmektedir.</p>",
    "budget": 7200,
    "deadline": "2025-04-15T00:00:00.000Z",
    "status": "open"
  },
  {
    "title": "Olay Tabanlı Mimari ve Event Sourcing",
    "description": "<p>Bankacılık uygulamamızın modernizasyonu kapsamında, hesap hareketlerinin sadece son durumunu değil, tüm tarihçesini değiştirilemez (immutable) bir şekilde saklamak istiyoruz. Bu amaçla, klasik CRUD yapısından, olayların (events) gerçeğin tek kaynağı olduğu 'Event Sourcing' mimarisine geçiş yapacağız.</p><p><strong>Mimari gereksinimler ve hedefler:</strong></p><ul><li><strong>Event Store Tasarımı:</strong> Tüm domain event'lerinin (ParaYatırıldı, ParaÇekildi, AdresDeğişti) kronolojik sırayla ve güvenli bir şekilde saklanacağı optimize edilmiş bir veritabanı yapısı kurulmalıdır.</li><li><strong>CQRS Ayrımı:</strong> Yazma (Command) ve Okuma (Query) modellerinin tamamen ayrıldığı, okuma tarafının yüksek performans için denormalize edildiği bir yapı (Materialized Views) oluşturulmalıdır.</li><li><strong>Event Replay:</strong> Olası bir sistem hatasında veya yeni bir raporlama ihtiyacında, geçmişteki tüm olayları yeniden oynatarak (replay) veritabanı durumunu sıfırdan oluşturabilecek araçlar geliştirilmelidir.</li><li><strong>Snapshotting:</strong> Performansı korumak adına, belirli sayıda olaydan sonra (örn: her 100 olayda bir) o anki durumun anlık görüntüsünü (snapshot) alan mekanizmalar eklenmelidir.</li><li><strong>Mesaj Dağıtımı:</strong> Olayların diğer mikroservislere güvenilir bir şekilde iletilmesi için Kafka veya RabbitMQ entegrasyonu sağlanmalıdır.</li></ul><p>Bu proje, yüksek veri tutarlılığı gerektirdiği için DDD (Domain Driven Design) prensiplerine hakim geliştiriciler aranmaktadır.</p>",
    "budget": 9800,
    "deadline": "2025-05-05T00:00:00.000Z",
    "status": "open"
  },
  {
    "title": "Kimlik Doğrulama ve Yetkilendirme Servisi",
    "description": "<p>Şirket bünyesindeki 10 farklı iç uygulama ve mobil uygulamalarımız için, kullanıcı yönetimini tek bir merkezden yapabileceğimiz, güvenli ve standartlara uygun bir 'Identity Provider' (IdP) servisi geliştirmek istiyoruz.</p><p><strong>Güvenlik ve fonksiyonellik taleplerimiz:</strong></p><ul><li><strong>SSO (Single Sign-On):</strong> Kullanıcıların bir kez giriş yaparak yetkili oldukları tüm uygulamalara erişebilmesini sağlayan merkezi oturum yönetimi kurulmalıdır.</li><li><strong>MFA (Çok Faktörlü Doğrulama):</strong> Giriş güvenliğini artırmak için Google Authenticator (TOTP) ve SMS tabanlı doğrulama seçenekleri sisteme entegre edilmelidir.</li><li><strong>RBAC ve İzin Yönetimi:</strong> Kullanıcı, Rol ve İzin (Permission) hiyerarşisinin dinamik olarak yönetilebildiği, her API çağrısında yetki kontrolü yapan middleware katmanları yazılmalıdır.</li><li><strong>Sosyal Girişler:</strong> Google, LinkedIn, GitHub ve Apple ile giriş yapma özellikleri OpenID Connect protokolü üzerinden desteklenmelidir.</li><li><strong>Audit Logging:</strong> Kimin, ne zaman, hangi IP'den giriş yaptığı, hatalı şifre denemeleri ve şifre değiştirme işlemleri gibi tüm güvenlik olayları silinemez loglarda tutulmalıdır.</li></ul><p>Şifre saklama politikaları (hashing algoritmaları, tuzlama vb.) en güncel güvenlik standartlarına (OWASP) uygun olmalı ve brute-force saldırılarına karşı hesap kilitleme mekanizmaları içermelidir.</p>",
    "budget": 5500,
    "deadline": "2025-04-08T00:00:00.000Z",
    "status": "open"
  },
  {
    "title": "Veri Analitik ve Raporlama Altyapısı",
    "description": "<p>Farklı veritabanlarında (MySQL, Mongo) ve üçüncü parti servislerde (reklam platformları, CRM) dağınık halde bulunan verilerimizi anlamlı iş zekası raporlarına dönüştürecek bir veri ambarı (Data Warehouse) pipeline'ı kurmak istiyoruz.</p><p><strong>Proje adımları ve beklentiler:</strong></p><ul><li><strong>ETL Süreçleri:</strong> Python veya Go kullanılarak, verileri kaynaklardan belirli periyotlarla çeken, temizleyen, standardize eden ve hedef veritabanına yükleyen sağlam script'ler yazılmalıdır.</li><li><strong>Performanslı Sorgulama:</strong> Analitik sorguların ana veritabanını yormaması için ClickHouse veya BigQuery gibi analitik veritabanı teknolojileri kullanılmalı ve şemalar buna göre tasarlanmalıdır.</li><li><strong>Önbellekleme (Caching):</strong> Yöneticilerin sık kullandığı dashboard verilerinin anlık gelmesi için Redis tabanlı agresif bir caching stratejisi uygulanmalıdır.</li><li><strong>Zamanlanmış Raporlar:</strong> Sistem, belirlenen şablonlara göre (Haftalık Satış, Aylık Churn vb.) otomatik raporlar oluşturup PDF/Excel formatında ilgili yöneticilere e-posta ile gönderebilmelidir.</li><li><strong>API Katmanı:</strong> Frontend ekibinin dashboard'ları besleyebilmesi için, karmaşık SQL sorgularını parametrik REST endpoint'lere dönüştüren bir API katmanı sunulmalıdır.</li></ul><p>Hassas verilerin (PII) raporlama ortamına taşınmadan önce maskelenmesi veya anonimleştirilmesi yasal bir zorunluluktur.</p>",
    "budget": 8200,
    "deadline": "2025-04-28T00:00:00.000Z",
    "status": "open"
  },
  {
    "title": "Mikroservis Orkestrasyon ve Koordinasyon",
    "description": "<p>Hızla büyüyen Kubernetes kümemizde çalışan 80+ mikroservisin yönetimi, izlenmesi ve birbirleriyle iletişimi artık manuel yöntemlerle sürdürülemez hale gelmiştir. Bu kaosu yönetilebilir bir yapıya kavuşturmak için Service Mesh teknolojilerini de içeren kapsamlı bir orkestrasyon katmanı tasarlanmasını istiyoruz.</p><p><strong>Sistemden beklentilerimiz:</strong></p><ul><li><strong>Service Discovery:</strong> Servislerin dinamik IP değişimlerinden etkilenmeden birbirlerini isimleriyle bulabilmesi için Consul veya Kubernetes native discovery mekanizmaları optimize edilmelidir.</li><li><strong>Resiliency Patterns:</strong> Bir servisin çökmesinin tüm sistemi etkilemesini önlemek için 'Circuit Breaker', 'Retry' ve 'Timeout' mekanizmaları tüm servis çağrılarına uygulanmalıdır.</li><li><strong>Distributed Tracing:</strong> Bir isteğin sisteme girişinden çıkışına kadar izlediği yolu ve harcadığı süreleri görebilmek için Jaeger veya Zipkin entegrasyonu yapılmalıdır.</li><li><strong>Merkezi Konfigürasyon:</strong> Tüm servislerin ayarlarını (DB şifreleri, API keyler) koddan ayırıp, Vault veya Spring Cloud Config gibi güvenli bir merkezden yöneten yapı kurulmalıdır.</li><li><strong>Sağlık Kontrolleri:</strong> Servislerin 'Liveness' ve 'Readiness' probe'larının doğru yapılandırılması ve problemli podların otomatik restart edilmesi sağlanmalıdır.</li></ul><p>Bu proje, DevOps ekibiyle yakın çalışmayı gerektirmekte olup, sistemin kod tarafındaki (backend) entegrasyon kütüphanelerinin yazılmasını da kapsamaktadır.</p>",
    "budget": 9900,
    "deadline": "2025-05-08T00:00:00.000Z",
    "status": "open"
  }
]